{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi_class Calssification  Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
    "\n",
    "X_train, X_valid, X_test = X_train / 255.0, X_valid / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(class_names[y_train[index]])\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        tf.keras.layers.Dense(300, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code â€“ this cell is equivalent to the previous cell\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    "    metrics=[tf.keras.metrics.sparse_categorical_accuracy],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=9, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(\n",
    "    figsize=(8, 5),\n",
    "    xlim=[0, 29],\n",
    "    ylim=[0, 1],\n",
    "    grid=True,\n",
    "    xlabel=\"Epoch\",\n",
    "    style=[\"r--\", \"r--.\", \"b-\", \"b-*\"],\n",
    ")\n",
    "plt.legend(loc=\"lower left\")  # extra code\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probabilities = model.predict(X_test[90:115])\n",
    "predictions = y_probabilities.argmax(axis=-1)\n",
    "np.array(class_names)[predictions]\n",
    "\n",
    "y_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = y_test[90:115]\n",
    "np.array(class_names)[actual]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42\n",
    ")\n",
    "\n",
    "X_train.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "\n",
    "model_reg = tf.keras.Sequential(\n",
    "    [\n",
    "        norm_layer,\n",
    "        tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.003)\n",
    "\n",
    "model_reg.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "\n",
    "norm_layer.adapt(X_train)\n",
    "history = model_reg.fit(\n",
    "    X_train, y_train, epochs=20, validation_data=(X_valid, y_valid), batch_size=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test, rmse_test = model_reg.evaluate(X_test, y_test)\n",
    "mse_test, rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest same data, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.63525  , 2.02629  , 2.03884  , 1.41593  , 0.8754   , 4.0508919,\n",
       "        3.783993 , 1.78361  , 4.0753917, 1.76857  ]),\n",
       " array([1.362  , 1.784  , 1.875  , 1.398  , 1.375  , 4.25   , 4.056  ,\n",
       "        1.388  , 5.00001, 1.621  ]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "preds = model.predict(X_test[15:25])\n",
    "\n",
    "\n",
    "preds, y_test[15:25]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide and Deep Neural net for California Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wide means input layer directly connected to output(concat)\n",
    "# Deep means 2+ hidden layer connected to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(4)\n",
    "\n",
    "# creating layers\n",
    "input_ = tf.keras.layers.Input(shape=X_train.shape[1:])\n",
    "norm_layer = tf.keras.layers.Normalization()\n",
    "dense_1 = tf.keras.layers.Dense(50, activation=\"relu\")\n",
    "dense_2 = tf.keras.layers.Dense(50, activation=\"relu\")\n",
    "concat = tf.keras.layers.Concatenate()\n",
    "output = tf.keras.layers.Dense(1)\n",
    "\n",
    "# creating the interconnections of layers\n",
    "\n",
    "normilized = norm_layer(input_)\n",
    "hidden1 = dense_1(normilized)\n",
    "hidden2 = dense_2(hidden1)\n",
    "concat = concat([normilized, hidden2])\n",
    "output = output(concat)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"RootMeanSquaredError\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_layer.adapt(X_train)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=15, validation_data=(X_valid, y_valid))\n",
    "\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide and Deep net with multiple inputs for Wide and Deep* (Regression example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(99)\n",
    "\n",
    "input_wide = tf.keras.layers.Input(name=\"wide_input\", shape=[5])\n",
    "input_deep = tf.keras.layers.Input(name=\"deep_input\", shape=[6])\n",
    "\n",
    "norm_layer_wide = tf.keras.layers.Normalization()\n",
    "norm_layer_deep = tf.keras.layers.Normalization()\n",
    "norm_wide = norm_layer_wide(input_wide)\n",
    "norm_deep = norm_layer_deep(input_deep)\n",
    "hidden_1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\n",
    "hidden_2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden_1)\n",
    "concat_ = tf.keras.layers.concatenate([norm_wide, hidden_2])\n",
    "\n",
    "output = tf.keras.layers.Dense(1)(concat_)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_wide, input_deep], outputs=[output])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"RootMeanSquaredError\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wide, X_train_deep, X_valid_wide, X_valid_deep, X_test_wide, X_test_deep = (\n",
    "    X_train[:, :5],\n",
    "    X_train[:, 2:],\n",
    "    X_valid[:, :5],\n",
    "    X_valid[:, 2:],\n",
    "    X_test[:, :5],\n",
    "    X_test[:, 2:],\n",
    ")\n",
    "\n",
    "norm_layer_wide.adapt(X_train_wide)\n",
    "norm_layer_deep.adapt(X_train_deep)\n",
    "\n",
    "history = model.fit(\n",
    "    (X_train_wide, X_train_deep),\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    validation_data=((X_valid_wide, X_valid_deep), y_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate((X_test_wide, X_test_deep), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide and Deep net with multiple inputs(wide and deep input) and Multiple outputs for Regularization (Regression example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(100)\n",
    "\n",
    "input_wide = tf.keras.layers.Input(name=\"wide_input\", shape=[5])\n",
    "input_deep = tf.keras.layers.Input(name=\"deep_input\", shape=[6])\n",
    "\n",
    "norm_layer_wide = tf.keras.layers.Normalization()\n",
    "norm_layer_deep = tf.keras.layers.Normalization()\n",
    "norm_wide = norm_layer_wide(input_wide)\n",
    "norm_deep = norm_layer_deep(input_deep)\n",
    "hidden_1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\n",
    "hidden_2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden_1)\n",
    "concat_ = tf.keras.layers.concatenate([norm_wide, hidden_2])\n",
    "\n",
    "output = tf.keras.layers.Dense(1, name=\"output_main\")(concat_)\n",
    "auxiliary_output = tf.keras.layers.Dense(1, name=\"output_aux\")(hidden_2)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=[input_wide, input_deep], outputs=[output, auxiliary_output]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=(\"mse\", \"mse\"),\n",
    "    loss_weights=(0.9, 0.1),\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"RootMeanSquaredError\"],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wide, X_train_deep, X_valid_wide, X_valid_deep, X_test_wide, X_test_deep = (\n",
    "    X_train[:, :5],\n",
    "    X_train[:, 2:],\n",
    "    X_valid[:, :5],\n",
    "    X_valid[:, 2:],\n",
    "    X_test[:, :5],\n",
    "    X_test[:, 2:],\n",
    ")\n",
    "\n",
    "norm_layer_wide.adapt(X_train_wide)\n",
    "norm_layer_deep.adapt(X_train_deep)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    (X_train_wide, X_train_deep),\n",
    "    (y_train, y_train),\n",
    "    epochs=20,\n",
    "    validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate((X_test_wide, X_test_deep), (y_test, y_test), return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_wide = X_test_wide[10:20]\n",
    "X_new_deep = X_test_deep[10:20]\n",
    "\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_wide, X_new_deep))\n",
    "\n",
    "y_pred_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subclassing API for dynamic models (Regression example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideDeepModel(tf.keras.Model):\n",
    "    def __init__(self, units = 30 , activation = 'relu', **kwargs):\n",
    "        super().__init__(**kwargs) # needed to support naming the model\n",
    "        self.norm_layer_wide = tf.keras.layers.Normalization()\n",
    "        self.norm_layer_deep = tf.keras.layers.Normalization()\n",
    "        self.hidden1 = tf.keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = tf.keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = tf.keras.layers.Dense(1)\n",
    "        self.aux_output = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs): \n",
    "        #if ...\n",
    "        input_wide, input_deep = inputs\n",
    "        norm_wide = self.norm_layer_wide(input_wide)\n",
    "        norm_deep = self.norm_layer_deep(input_deep)\n",
    "        hidden1 = self.hidden1(norm_deep)\n",
    "        # while len(hidden1)...\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        #return inverse(main_output).... Etc.\n",
    "\n",
    "        return main_output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wide, X_train_deep, X_valid_wide, X_valid_deep, X_test_wide, X_test_deep = (\n",
    "    X_train[:, :5],\n",
    "    X_train[:, 2:],\n",
    "    X_valid[:, :5],\n",
    "    X_valid[:, 2:],\n",
    "    X_test[:, :5],\n",
    "    X_test[:, 2:],\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=(\"mse\", \"mse\"), loss_weights=[0.9, 0.1], optimizer=optimizer,\n",
    "              metrics=[\"RootMeanSquaredError\"])\n",
    "\n",
    "model.norm_layer_wide.adapt(X_train_wide)\n",
    "model.norm_layer_deep.adapt(X_train_deep)\n",
    "\n",
    "history = model.fit(\n",
    "    (X_train_wide, X_train_deep), (y_train, y_train), epochs=10,\n",
    "    validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid)))\n",
    "eval_results = model.evaluate((X_test_wide, X_test_deep), (y_test, y_test))\n",
    "weighted_sum_of_losses, main_loss, aux_loss, main_rmse, aux_rmse = eval_results\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model and using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42\n",
    ")\n",
    "\n",
    "X_train_wide, X_train_deep, X_valid_wide, X_valid_deep, X_test_wide, X_test_deep = (\n",
    "    X_train[:, :5],\n",
    "    X_train[:, 2:],\n",
    "    X_valid[:, :5],\n",
    "    X_valid[:, 2:],\n",
    "    X_test[:, :5],\n",
    "    X_test[:, 2:],\n",
    ")\n",
    "\n",
    "X_new_wide, X_new_deep = X_test_wide[15:25], X_test_deep[15:25]\n",
    "\n",
    "# Y_test[15:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  \n",
    "model = WideDeepModel(30, activation=\"relu\", name=\"my_cool_model\")\n",
    "model.compile(loss=(\"mse\", \"mse\"), loss_weights=[0.9, 0.1], optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=[\"RootMeanSquaredError\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.norm_layer_wide.adapt(X_train_wide)\n",
    "model.norm_layer_deep.adapt(X_train_deep)\n",
    "\n",
    "history = model.fit(\n",
    "    (X_train_wide, X_train_deep), (y_train, y_train), epochs=20,\n",
    "    validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid)))\n",
    "\n",
    "\n",
    "model.save('hausing_widedeep_model', save_format='tf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 17:45:11.746733: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1.3304222],\n",
       "        [2.456015 ],\n",
       "        [2.0427592],\n",
       "        [2.227831 ],\n",
       "        [1.1571676],\n",
       "        [2.8501782],\n",
       "        [2.5904763],\n",
       "        [1.735521 ],\n",
       "        [3.253336 ],\n",
       "        [2.180563 ]], dtype=float32),\n",
       " array([1.362  , 1.784  , 1.875  , 1.398  , 1.375  , 4.25   , 4.056  ,\n",
       "        1.388  , 5.00001, 1.621  ]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('hausing_widedeep_model')\n",
    "\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_wide, X_new_deep))\n",
    "\n",
    "\n",
    "y_pred_main, y_test[15:25]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
